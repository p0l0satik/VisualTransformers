{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "9kNOzyKxLK4J"
      },
      "source": [
        "# Compact Convolutional Transformers (10 points)\n",
        "\n",
        "In this task you will train Vision Transformer-like network for cifar10 images classification.\n",
        "\n",
        "This task is based on paper [Escaping the Big Data Paradigm with Compact Transformers](https://arxiv.org/pdf/2104.05704.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSB4KmonQo6f"
      },
      "source": [
        "By implementing all the missing code snippets you can get 10 points. Good luck!\n",
        "\n",
        "\n",
        "![изображение.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqteQtJoLK4M"
      },
      "source": [
        "## CIFAR dataset\n",
        "\n",
        "You have already met this dataset in seminars.\n",
        "\n",
        "* 60k images of shape 3x32x32\n",
        "* 10 different classes: planes, dogs, cats, trucks, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLqszutaLK4O"
      },
      "outputs": [],
      "source": [
        "# when running in colab, un-comment this\n",
        "!wget https://cloud.imm.uran.ru/s/XCdWoSSK3wyeHYE/download/cifar.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y78LNviaLK4P"
      },
      "outputs": [],
      "source": [
        "#!L\n",
        "import numpy as np\n",
        "import random\n",
        "from cifar import load_cifar10\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10(\"cifar_data\")\n",
        "\n",
        "class_names = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                        'dog', 'frog', 'horse', 'ship', 'truck'])\n",
        "\n",
        "print(X_train.shape,y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFFDp5YXLK4R"
      },
      "outputs": [],
      "source": [
        "#!L\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=[12,10])\n",
        "for i in range(12):\n",
        "    plt.subplot(3,4,i+1)\n",
        "    plt.imshow(np.transpose(X_train[i],[1,2,0]))\n",
        "    plt.title(class_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-cQbu8xLK4S"
      },
      "source": [
        "## Prepare dataset and loss\n",
        "\n",
        "The following code is based on homework 1-pt2 and should be familiar to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crrT5dSjLK4T"
      },
      "outputs": [],
      "source": [
        "#!L\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8os_etl6LK4U"
      },
      "outputs": [],
      "source": [
        "#!L\n",
        "def get_computing_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "    return device\n",
        "\n",
        "device = get_computing_device()\n",
        "print(f\"Our main computing device is '{device}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2cc1TWrLK4V"
      },
      "outputs": [],
      "source": [
        "#!L\n",
        "def compute_loss(logits, y_batch):\n",
        "    return F.cross_entropy(logits, y_batch).mean().cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P1yB8pULK4X"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "means = np.array((0.4914, 0.4822, 0.4465))\n",
        "stds = np.array((0.2470, 0.2435, 0.2616))\n",
        "\n",
        "transform_augment = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((32,32), scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
        "    transforms.RandomRotation([-5, 5]),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
        "    transforms.Normalize(means, stds),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(means, stds),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZSYESpNLK4Y"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "NUM_WORKERS = 16\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "train_loader = CIFAR10(\"./cifar_data/\", train=True, transform=transform_augment)\n",
        "\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_loader, \n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=NUM_WORKERS)\n",
        "val_loader = CIFAR10(\"./cifar_data/\", train=False, transform=transform_test)\n",
        "\n",
        "val_batch_gen = torch.utils.data.DataLoader(val_loader, \n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              shuffle=False,\n",
        "                                              num_workers=NUM_WORKERS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6hE6ckbLK4Z"
      },
      "source": [
        "## Task 1. Multi-head attention\n",
        "\n",
        "Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyjPoMNGLK4a"
      },
      "source": [
        "<img src=\"https://data-science-blog.com/wp-content/uploads/2022/01/mha_img_original.png\" style=\"width:50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ckOmkwkLK4a"
      },
      "source": [
        "Let's implement MultiHeadAttention for beggining. It's already implemented in pytorch, so we will use `nn.MultiHeadAttention` for testing of your implementation.\n",
        "\n",
        "As a reminder, (one-head) attention implements a simple formula: $\\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$, where $d_k$ is size of K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bgWERcaF1h9"
      },
      "source": [
        "**Tip: read about how the torch.matmul and torch.t methods work. Think about how they will work for batches and what dimension the tensors will have.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJyo2-zJLK4b"
      },
      "outputs": [],
      "source": [
        "# Complete CustomMultiHeadSelfAttention in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZp24TryLK4c"
      },
      "source": [
        "Let's check that your implementation works like `torch.nn.MultiheadAttention`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbd7uGjhwUcW"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VtWJhvKwUcW"
      },
      "outputs": [],
      "source": [
        "from modules import * # CustomMultiHeadSelfAttention, StepLRWithWarmup,\n",
        "                        #TokenizerCCT, SeqPooling, create_mlp, DropPath, TransformerEncoder, CompactConvTransformer3x1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO-R9omdLK4c"
      },
      "outputs": [],
      "source": [
        "mha = torch.nn.MultiheadAttention(embed_dim=128, num_heads=16, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCfFNmVpLK4d"
      },
      "outputs": [],
      "source": [
        "custom_mha = CustomMultiHeadSelfAttention(embed_dim=128, num_heads=16)\n",
        "custom_mha.in_proj.weight = mha.in_proj_weight\n",
        "custom_mha.in_proj.bias = mha.in_proj_bias\n",
        "custom_mha.out_proj.weight = mha.out_proj.weight\n",
        "custom_mha.out_proj.bias = mha.out_proj.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdyczd4wLK4d"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "for _ in range(100):\n",
        "    a = torch.rand((1, 10, 128))\n",
        "    out1 = mha(a, a, a)[0].cpu().detach().numpy()\n",
        "    out2 = custom_mha(a).cpu().detach().numpy()\n",
        "    assert np.allclose(out1, out2, atol=1e-6), f\"{out1} {out2}\"\n",
        "    \n",
        "print (\"Congratulations! It works!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXvU8LDvLK4d"
      },
      "source": [
        "## Task 2: Step-wise learning rate with warm-up\n",
        "\n",
        "Your task is to implement class that works as `torch.optim.lr_scheduler.StepLR` but supports warm-up.\n",
        "\n",
        "First of all, examine the docstring and implementation of `StepLR` scheduler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gib565nLLK4d"
      },
      "outputs": [],
      "source": [
        "torch.optim.lr_scheduler.StepLR??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUgwnNPDLK4d"
      },
      "source": [
        "Then implement `get_lr()` method. It should work as following:\n",
        "1. If `self.last_epoch` is in `[0, self.warmup_epochs)`, then scheduler is in warm-up mode and learning rate should lineary increase during epochs from `self.warmup_lr_init` to `self.base_lrs` (which is the original learning rate of optimizer)\n",
        "2. If `self.last_epoch` is equal to `self.warmup_epochs`, then just return `self.base_lrs`.\n",
        "3. If `self.last_epoch - self.warmup_epochs` is not divisible by `self.step_size` then just return the previous learning rate which is available through `[group['lr'] for group in self.optimizer.param_groups]`\n",
        "4. If `self.last_epoch - self.warmup_epochs` is divisible by `self.step_size` and the current learning rate multiplied by `self.gamma` is not less then self.min_lr, then multiply it and return the new value.\n",
        "5. Otherwise just return the last learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbKxlfXFLK4e"
      },
      "outputs": [],
      "source": [
        "# Complete class StepLRWithWarmup in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVI2W5UvLK4e"
      },
      "source": [
        "Let's check what you have written.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdipDSNsLK4f"
      },
      "outputs": [],
      "source": [
        "WARMUP_LR_INIT = 1e-5\n",
        "WARMUP_EPOCHS = 10\n",
        "STEP_SIZE = 10\n",
        "GAMMA = 0.1\n",
        "MIN_LR = 1e-5\n",
        "OPT_LR = 1e-3\n",
        "\n",
        "dummy_net = nn.Sequential(nn.Linear(10,10))\n",
        "dummy_opt = torch.optim.Adam(dummy_net.parameters(), lr=OPT_LR)\n",
        "\n",
        "scheduler = StepLRWithWarmup(dummy_opt, step_size=STEP_SIZE, gamma=GAMMA, \n",
        "                                      warmup_epochs=WARMUP_EPOCHS, warmup_lr_init=WARMUP_LR_INIT,\n",
        "                                      min_lr=MIN_LR)\n",
        "\n",
        "# we need to do at least one optimizer step before calling scheduler.step()\n",
        "# in order to make pytorch happy\n",
        "dummy_opt.step()  \n",
        "\n",
        "\n",
        "learning_rates = []\n",
        "for i in range(100):\n",
        "    learning_rates.append(scheduler.get_last_lr())\n",
        "    scheduler.step()\n",
        "    \n",
        "plt.plot(learning_rates)\n",
        "plt.grid()\n",
        "plt.title('Learning rates')\n",
        "    \n",
        "assert np.isclose(learning_rates[0], WARMUP_LR_INIT), \\\n",
        "    f\"LR on the first epoch should be equal to {WARMUP_LR_INIT}, actual value {learning_rates[0]}\"\n",
        "assert np.isclose(learning_rates[WARMUP_EPOCHS], OPT_LR), \\\n",
        "    f\"LR after warmup shold be equal to {OPT_LR}, actual value {learning_rates[WARMUP_EPOCHS]}\"\n",
        "assert np.isclose(learning_rates[WARMUP_EPOCHS+STEP_SIZE-1], OPT_LR), \\\n",
        "    f\"LR after warmup + (STEP_SIZE-1) steps should be equal to {OPT_LR}, \"\\\n",
        "    f\"actual value {learning_rates[WARMUP_EPOCHS+STEP_SIZE-1]}\"\n",
        "assert np.isclose(learning_rates[WARMUP_EPOCHS+STEP_SIZE], OPT_LR*GAMMA), \\\n",
        "    f\"LR after warmup + (STEP_SIZE) steps shold be equal to {OPT_LR*GAMMA}, \" \\\n",
        "    f\"actual value {learning_rates[WARMUP_EPOCHS+STEP_SIZE]}\"\n",
        "\n",
        "assert np.isclose(learning_rates[WARMUP_EPOCHS+STEP_SIZE*2-1], OPT_LR*GAMMA), \\\n",
        "    f\"LR after warmup + (2*STEP_SIZE-1) steps should be equal to {OPT_LR*GAMMA}, \"\\\n",
        "    f\"actual value {learning_rates[WARMUP_EPOCHS+STEP_SIZE*2-1]}\"\n",
        "assert np.isclose(learning_rates[WARMUP_EPOCHS+2*STEP_SIZE], OPT_LR*GAMMA**2), \\\n",
        "    f\"LR after warmup + (2*STEP_SIZE) steps shold be equal to {OPT_LR*GAMMA**2}, \" \\\n",
        "    f\"actual value {learning_rates[WARMUP_EPOCHS+2*STEP_SIZE]}\"\n",
        "\n",
        "assert np.isclose(learning_rates[WARMUP_EPOCHS+3*STEP_SIZE], OPT_LR*GAMMA**2), \\\n",
        "    f\"LR after warmup + (3*STEP_SIZE) steps shold be equal to {OPT_LR*GAMMA**2}, \" \\\n",
        "    f\"actual value {learning_rates[WARMUP_EPOCHS+3*STEP_SIZE]}\"\n",
        "\n",
        "for i in range(WARMUP_EPOCHS):\n",
        "    expected_val = WARMUP_LR_INIT + i*(OPT_LR-WARMUP_LR_INIT) / WARMUP_EPOCHS\n",
        "    actual_val = learning_rates[i]\n",
        "    assert np.isclose(actual_val, expected_val), \\\n",
        "        f\"LR should linary increase from {WARMUP_LR_INIT} to {OPT_LR} during warmup.\"\\\n",
        "        f\"Expected: {expected_val}, actual: {actual_val}, iteration={i}\"\n",
        "assert all(elem[0] >= MIN_LR for elem in learning_rates)\n",
        "print(\"All asserts were passed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJg5Lc_oLK4g"
      },
      "source": [
        "## Task 3. Compact Convolutional Transformer\n",
        "\n",
        "During seminar you learned the main components of vision transformer: Tokenizer, Transformer encoder, position embeddings. At this point, it's expected that you have solved the ipython notebook from the seminar. If you didn't, then you know what to do before starting the current task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwkt9-uGLK4h"
      },
      "source": [
        "Your task is to implement Compact Convolutional Transformer (CCT). It has two main changes comparing to the original ViT that was implemented during seminar. The first one is in tokenizer. Authors of CCT suggested to apply the first convolution with stride=1 allowing transformer to work with input patches that overlaps with each other. Since simple removing of stride increases the spatial resolution of the input tensor, we use MaxPool2d with desired stride in order to reduce the number of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nGlFaOILK4h"
      },
      "outputs": [],
      "source": [
        "# Complete class TokenizerCCT in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGdR8Gh4LK4h"
      },
      "source": [
        "The second change is that CCT uses learnable pooling instead of class token for global features extraction. Its formula is similar to attention formula:\n",
        "$$y = \\text{softmax}(WX^T+b) * X$$\n",
        "where $X$ - layer input - matrix of shape [batch_size, n_tokens, n_embedding], $W$, $b$ - learnable parameters, that transform each token embedding vector to 1 element (in fact it's just a linear layer with output_dim=1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWVqYC4bLK4i"
      },
      "outputs": [],
      "source": [
        "# Complete class SeqPooling in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICBxJ5SHLK4i"
      },
      "source": [
        "### The following three modules were implemented by you during seminar, so you can just copy-paste their implementations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr5gwHkfDXgC"
      },
      "source": [
        "MLP for transformer encoder is just a simple two-layer perceptron with GELU as non-linearity. It also uses Dropout after each Linear layer in order to reduce overfitting. Important thing is that size of hidden state on MLP is usually several times bigger than size of MLP input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TduBPQKLK4i"
      },
      "outputs": [],
      "source": [
        "# Complete create_mlp function in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i30dDoPrFrAA"
      },
      "source": [
        "Let's implement `DropPath` module. Its only parameter is `drop_prob` - probability to zero-out its input. Don't forget to devide the result on `(1-drop_prob)` in order to fix mean value of output in train mode (as you did in the first homework in dropout implementation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AyEGPWLLK4j"
      },
      "outputs": [],
      "source": [
        "# Complete class DropPath in modules.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNTxAJqDLK4j"
      },
      "outputs": [],
      "source": [
        "# Complete class TransformerEncoder in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7hK_RjhLK4j"
      },
      "source": [
        "The final class for the CCT. It looks the same as `VisionTransformer` class in seminar notebook, except the custom tokenizer and pooling. Here we implement a simple version of CCT, whose Tokenizer consist of one convolution of 3x3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9sCqNb1LK4k"
      },
      "outputs": [],
      "source": [
        "# Complete class CompactConvTransformer3x1 in modules.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1s5t7NsLK4k"
      },
      "source": [
        "## Final training \n",
        "\n",
        "If everything was implemented correctly, the following code will give you a model with > 84.5% accuracy (in fact it should be ~87.5%). If you see a smaller number, check your implementation of modules above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTQNxfQHLK4l"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "model = CompactConvTransformer3x1(input_height=32, input_width=32, n_tokens=16, n_input_channels=3, \n",
        "                                  embedding_dim=128, num_layers=4, num_heads=4, num_classes=10, mlp_ratio=2)\n",
        "model = model.to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
        "scheduler = StepLRWithWarmup(opt, 40, gamma=0.3, warmup_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI5Z8FFxLK4l",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "num_epochs = 120 # total amount of full passes over training data\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # In each epoch, we do a full pass over the training data:\n",
        "    start_time = time.time()\n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    train_loss = []\n",
        "    val_accuracy = []\n",
        "    \n",
        "    for X_batch, y_batch in tqdm_notebook(train_batch_gen): # or train_batch_gen\n",
        "        opt.zero_grad()\n",
        "        # train on batch\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        \n",
        "        logits = model(X_batch)\n",
        "        loss = compute_loss(logits, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        train_loss.append(loss.data.numpy())\n",
        "    print (scheduler.get_last_lr())\n",
        "    scheduler.step()\n",
        "        \n",
        "    # And a full pass over the validation data:\n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in tqdm_notebook(val_batch_gen): # or val_batch_gen\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.numpy()\n",
        "        logits = model(X_batch).cpu()\n",
        "        y_pred = logits.max(1)[1].data.numpy()\n",
        "        val_accuracy.append(np.mean(y_batch == y_pred))\n",
        "\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
        "        epoch + 1, num_epochs, time.time() - start_time))\n",
        "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
        "        np.mean(train_loss)))\n",
        "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
        "        np.mean(val_accuracy) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_1i2j9VwUce"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hw2_transformers_Surname_Name_attempt_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}